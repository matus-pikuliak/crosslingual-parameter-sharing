{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('martak', 108), ('gcp', 62), ('deepnet2', 83), ('fiit-gcp-1', 10), ('fiit-gcp-2', 13), ('fiit-gcp-3', 14), ('acer', 32), ('deepnet2070', 10)]\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from run import Run\n",
    "from runs_db import db as runs_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fiit/logs/deepnet2070/2019-03-29-050040\n"
     ]
    }
   ],
   "source": [
    "log_path = '/home/fiit/logs'\n",
    "runs = []\n",
    "\n",
    "for server in runs_db:\n",
    "    paths = glob.glob(os.path.join(log_path, server, '*'))\n",
    "    paths = iter(sorted(paths))\n",
    "\n",
    "    try:\n",
    "        for (number, type_, code) in runs_db[server]:\n",
    "            for _ in range(number):\n",
    "                try:\n",
    "                    path = next(paths)\n",
    "                    runs.append(Run(path, type_, code))\n",
    "                except KeyError:\n",
    "                    print(path)\n",
    "    except StopIteration:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['dep', 'lmo', 'ner', 'pos']\n",
    "langs = ['cs', 'de', 'en', 'es']\n",
    "\n",
    "task_metr = {\n",
    "    'dep': 'las',\n",
    "    'lmo': 'perplexity',\n",
    "    'ner': 'chunk_f1',\n",
    "    'pos': 'acc'\n",
    "}\n",
    "\n",
    "task_max = {\n",
    "    'dep': True,\n",
    "    'lmo': False,\n",
    "    'ner': True,\n",
    "    'pos': True\n",
    "}\n",
    "\n",
    "def draw_graphs(metric_func, tasks, langs, role, run_codes=None, run_types=None):\n",
    "    fig, axes = plt.subplots(len(tasks), len(langs), figsize=(5*len(langs), 4*len(tasks)), squeeze=False)\n",
    "\n",
    "    relevant_runs = ['vanilla']\n",
    "\n",
    "    for task, lang in itertools.product(tasks, langs):\n",
    "        for run in runs:\n",
    "            if (\n",
    "                run.contains(task, lang) and\n",
    "                (run_codes is None or run.code in run_codes) and\n",
    "                (run_types is None or run.type in run_types)\n",
    "            ):\n",
    "\n",
    "                history = run.history(\n",
    "                    metric=metric_func(task),\n",
    "                    task=task,\n",
    "                    language=lang,\n",
    "                    role=role)\n",
    "                axes[tasks.index(task), langs.index(lang)].plot(list(history), label=f'{run.code}-{run.type}')\n",
    "\n",
    "    for ax, col in zip(axes[0], langs):\n",
    "        ax.set_title(col)\n",
    "\n",
    "    for ax, row in zip(axes[:, 0], tasks):\n",
    "        ax.set_ylabel(row, rotation=0, size='large')\n",
    "        \n",
    "    for ax_row in axes:\n",
    "        for ax in ax_row:\n",
    "            ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def print_results(metric_func, metric_max_func, tasks, langs, run_codes=None, run_types=None, print_lambda=None):\n",
    "    \n",
    "    if print_lambda is None:\n",
    "        print_lambda = lambda val, run: print(f'{val:.2f}')\n",
    "        \n",
    "    output = []\n",
    "    \n",
    "    for task, lang in itertools.product(tasks, langs):\n",
    "        for run in runs:\n",
    "            if (\n",
    "                run.contains(task, lang) and\n",
    "                (run_codes is None or run.code in run_codes) and\n",
    "                (run_types is None or run.type in run_types)\n",
    "            ):\n",
    "                result = run.metric_eval(\n",
    "                    metric=metric_func(task),\n",
    "                    max_=metric_max_func(task),\n",
    "                    task=task,\n",
    "                    language=lang)\n",
    "                res = result[0]\n",
    "                if res < 1.01:\n",
    "                    res *= 100\n",
    "                print_lambda(res, run)\n",
    "                output.append((res, run))\n",
    "                \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dep cs\n",
      "[(0.8879265897728523, ('dep', 'es')), (0.8871039688562673, ('dep', 'es')), (0.8863045203598677, ('dep', 'de'))]\n",
      "dep es\n",
      "[(0.8670044331855605, ('dep', 'en')), (0.8667330136614494, ('dep', 'cs')), (0.865647335565005, ('dep', 'de'))]\n",
      "ner cs\n",
      "[(0.7877138413685848, ('dep', 'cs')), (0.7861635220125787, ('ner', 'en')), (0.7839433293978749, ('pos', 'cs'))]\n",
      "ner es\n",
      "[(0.8768634466308887, ('lmo', 'es')), (0.872039326679577, ('ner', 'de')), (0.8662192393736018, ('ner', 'cs'))]\n",
      "pos cs\n",
      "[(99.0360273202834, ('dep', 'cs')), (98.97635833830574, ('lmo', 'cs')), (98.9694066122501, ('ner', 'cs'))]\n",
      "pos es\n",
      "[(96.8605808377816, ('pos', 'en')), (96.7701076630779, ('pos', 'de')), (96.75201302813716, ('pos', 'cs'))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pair_runs = [run for run in runs if run.code == 'one-aux']\n",
    "for task, lang in itertools.product(['dep', 'ner', 'pos'], ['cs', 'es']):\n",
    "    results = []\n",
    "    for r in pair_runs:\n",
    "        if r.contains(task, lang):\n",
    "            score, _ = r.metric_eval(task_metr[task], task_max[task], task=task, language=lang)\n",
    "            l = list(r.hparams['tasks'])\n",
    "            l.remove((task, lang))\n",
    "            results.append((score, l[0]))\n",
    "    print(task, lang)\n",
    "    print(sorted(results, key=lambda x: -x[0])[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['pos'], ['sk'],\n",
    "    print_lambda=lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "print()\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['sk'],\n",
    "    print_lambda=lambda val, run: print(f'{val:.2f} {run.path}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['cs'],\n",
    "     ['private-focused-0.75'], ['ml'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['es'],\n",
    "     ['private-focused'], ['ml'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['ner'], ['cs'],\n",
    "     ['vanilla'], ['mt'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print('87.69 /home/fiit/logs/acer/2019-02-22-025619')\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['pos'], ['cs'],\n",
    "     ['no-adv-tsh-focused-0.75'], ['mt'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['pos'], ['es'],\n",
    "     ['no-adv-tsh-focused'], ['mt'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print()\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['de'],\n",
    "     ['private'], ['mt'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['en'],\n",
    "     ['private'], ['ml'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print('83.07 /home/fiit/logs/deepnet2/2019-02-26-041529')\n",
    "print('85.07 /home/fiit/logs/acer/2019-02-20-213852')\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['pos'], ['de'],\n",
    "     ['vanilla'], ['mt'], print_lambda=lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['pos'], ['en'],\n",
    "     ['private'], ['mt'], print_lambda=lambda val, run: print(f'{val:.2f} {run.path}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graphs(lambda task: task_metr[task], tasks, langs, 'test',\n",
    "#              ['private-focused-200', 'no-adv-tsh-200'], ['ml'])\n",
    "draw_graphs(lambda task: task_metr[task], tasks, langs, 'test',\n",
    "             ['vanilla', 'no-mwe'], ['ml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [('dep','cs'), ('dep','es'), ('ner','cs'), ('ner','es'), ('pos','cs'), ('pos','es'),]\n",
    "\n",
    "def print_row(code, type_):\n",
    "    for t, l in pairs:\n",
    "        print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                    [code], [type_], lambda val, run: print(f'{val:.2f}', end=' '))\n",
    "\n",
    "codes = ['private-focused', 'no-adv-tsh-focused']\n",
    "types = ['ml', 'mt']\n",
    "\n",
    "print('baseline 89.16 86.51 78.10 86.77 98.89 96.46')\n",
    "print('best unfocused 89.16 86.70 81.58 87.69 99.04 96.87')\n",
    "\n",
    "\n",
    "for code in codes:\n",
    "    for type_ in types:\n",
    "        print(f'{code}{type_}', end='\\t')\n",
    "        print_row(code, type_)\n",
    "        print()\n",
    "        \n",
    "codes = ['private-focused-0.75', 'no-adv-tsh-focused-0.75']\n",
    "types = ['ml', 'mt']\n",
    "\n",
    "for code in codes:\n",
    "    for type_ in types:\n",
    "        print(f'{code}{type_}', end='\\t\\t')\n",
    "        print_row(code, type_)\n",
    "        print()\n",
    "        \n",
    "codes = ['private-focused-0.75', 'no-adv-tsh-focused-0.75', 'private-focused', 'no-adv-tsh-focused']\n",
    "types = ['mtml']\n",
    "\n",
    "for code in codes:\n",
    "    for type_ in types:\n",
    "        print(f'{code}{type_}', end='\\t\\t')\n",
    "        print_row(code, type_)\n",
    "        print()\n",
    "\n",
    "\n",
    "# print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['en'],\n",
    "#             ['dep-adv-lambda-0.25'])\n",
    "# print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['en'],\n",
    "#             ['dep-adv-lambda-0.125'])\n",
    "# print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['en'],\n",
    "#             ['no-adv-task-sharing'], ['ml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pairs = list(itertools.product(['dep', 'ner', 'pos'], langs))\n",
    "\n",
    "def print_row(code, type_, msg):\n",
    "    print(msg, end=' ')\n",
    "    for t, l in pairs:\n",
    "        print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                    [code], [type_], lambda val, run: print(f'{val:.2f}', end=' '))\n",
    "    print()\n",
    "        \n",
    "print_row('vanilla', 'stsl', 'Baseline')\n",
    "\n",
    "print('Best1', end=' ')\n",
    "for t, l in pairs:\n",
    "    output = print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                ['one-aux'], print_lambda=lambda _, __: ...)\n",
    "    print(f'{max([r[0] for r in output]):.2f}', end=' ')\n",
    "print()\n",
    "\n",
    "print('Avg', end=' ')\n",
    "for t, l in pairs:\n",
    "    output = print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                ['one-aux'], print_lambda=lambda _, __: ...)\n",
    "    print(f'{np.mean([r[0] for r in output]):.2f}', end=' ')\n",
    "print()\n",
    "\n",
    "\n",
    "print('Worst1', end=' ')\n",
    "for t, l in pairs:\n",
    "    output = print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                ['one-aux'], print_lambda=lambda _, __: ...)\n",
    "    print(f'{min([r[0] for r in output]):.2f}', end=' ')\n",
    "print()\n",
    "\n",
    "print_row('vanilla', 'mt', 'A-MT')\n",
    "print_row('no-adv-task-sharing', 'ml', 'A-ML')\n",
    "print_row('no-adv-task-sharing', 'mtml', 'A-MTML')\n",
    "print_row('private', 'mt', 'B-MT')\n",
    "print_row('private', 'ml', 'B-ML')\n",
    "print_row('private', 'mtml', 'B-MTML')\n",
    "print_row('no-adv', 'ml', 'C-ML')\n",
    "print_row('no-adv', 'mtml', 'C-MTML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t, l in pairs:\n",
    "    output = print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                ['one-aux'], print_lambda=lambda _, __: ...)\n",
    "    output = sorted(output, key=lambda r: -r[0])\n",
    "    print(output[0][1].hparams['tasks'])\n",
    "    #print(f'{max([r[0] for r in output]):.2f}', end=' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graphs(lambda task: task_metr[task], tasks, langs, 'test', ['vanilla'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], tasks, langs,\n",
    "     ['fine-tune'], print_lambda=lambda val, run: print(f'{val:.2f} {run.hparams[\"train_only\"]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_results(task, lang):\n",
    "    \n",
    "    code_types = [\n",
    "        ('vanilla-200', 'stsl'),\n",
    "        ('vanilla-2000', 'stsl'),\n",
    "        ('vanilla', 'stsl'),\n",
    "        ('no-adv-tsh-200', 'mt'),\n",
    "        ('no-adv-tsh-2000', 'mt'),\n",
    "        ('vanilla', 'mt'),\n",
    "        ('no-adv-tsh-200', 'ml'),\n",
    "        ('no-adv-tsh-2000', 'ml'),\n",
    "        ('no-adv-task-sharing', 'ml'),\n",
    "        ('no-adv-tsh-200', 'mtml'),\n",
    "        ('no-adv-tsh-2000', 'mtml'),\n",
    "        ('no-adv-task-sharing', 'mtml'),\n",
    "\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    for code, type_ in code_types:\n",
    "\n",
    "        output = print_results(lambda task: task_metr[task], lambda task: task_max[task], [task], [lang],\n",
    "         [code], [type_], print_lambda=lambda val, run: ...)\n",
    "        for res, run in output:\n",
    "            if run.hparams['limited_task_language'] in [f'{task}-{lang}', None]:\n",
    "                yield res\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(20, 3), squeeze=False)\n",
    "\n",
    "sizes = {\n",
    "    ('dep', 'cs'): 67900,\n",
    "    ('dep', 'es'): 14000,\n",
    "    ('ner', 'cs'): 7100,\n",
    "    ('ner', 'es'): 6900, \n",
    "    ('pos', 'cs'): 67900,  \n",
    "    ('pos', 'es'): 14000,\n",
    "}\n",
    "\n",
    "titles = {\n",
    "    ('dep', 'cs'): 'DP-cs',\n",
    "    ('dep', 'es'): 'DP-es',\n",
    "    ('ner', 'cs'): 'NER-cs',\n",
    "    ('ner', 'es'): 'NER-es', \n",
    "    ('pos', 'cs'): 'POS-cs',  \n",
    "    ('pos', 'es'): 'POS-es',    \n",
    "}\n",
    "\n",
    "for i, (t, l) in enumerate(itertools.product(['dep', 'ner', 'pos'], ['cs', 'es'])):\n",
    "    results = list(yield_results(t, l))\n",
    "    axes[0, i].plot([200,2000,sizes[t, l]], results[0:3])\n",
    "    axes[0, i].plot([200,2000,sizes[t, l]], results[3:6])\n",
    "    axes[0, i].plot([200,2000,sizes[t, l]], results[6:9])  \n",
    "    axes[0, i].plot([200,2000,sizes[t, l]], results[9:12])\n",
    "    axes[0, i].set_xscale('log')\n",
    "    axes[0, i].set_xticks([200,2000,sizes[t, l]])\n",
    "    axes[0, i].set_xticklabels(['200', '2000', 'full'])\n",
    "    axes[0, i].set_title(titles[t, l])\n",
    "    axes[0, i].set_xlabel('train size')\n",
    "\n",
    "    \n",
    "axes[0,0].set_ylabel('performance')\n",
    "    \n",
    "\n",
    "#           ax.set_title(col)\n",
    "\n",
    "#     for ax, row in zip(axes[:, 0], tasks):\n",
    "#         ax.set_ylabel(row, rotation=0, size='large')\n",
    "        \n",
    "#     for ax_row in axes:\n",
    "#         for ax in ax_row:\n",
    "#             ax.legend()\n",
    "  \n",
    "\n",
    "# for ax, col in zip(axes[0], langs):\n",
    "#     ax.set_title(col)\n",
    "\n",
    "# for ax, row in zip(axes[:, 0], tasks):\n",
    "#     ax.set_ylabel(row, rotation=0, size='large')\n",
    "\n",
    "# for ax_row in axes:\n",
    "#     for ax in ax_row:\n",
    "#         ax.legend()\n",
    "\n",
    "plt.savefig('sample.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
