{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('deepnet5', 216), ('deepnet2070', 144)]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from run import Run\n",
    "from runs_db import db as runs_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = '/home/fiit/logs'\n",
    "runs = []\n",
    "\n",
    "for server in runs_db:\n",
    "    paths = glob.glob(os.path.join(log_path, server, '*'))\n",
    "    paths = iter(sorted(paths))\n",
    "\n",
    "    try:\n",
    "        for (number, type_, code) in runs_db[server]:\n",
    "            for _ in range(number):\n",
    "                try:\n",
    "                    path = next(paths)\n",
    "                    runs.append(Run(path, type_, code))\n",
    "                except KeyError:\n",
    "                    print(path)\n",
    "    except StopIteration:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['dep', 'lmo', 'ner', 'pos']\n",
    "langs = ['cs', 'de', 'en', 'es']\n",
    "\n",
    "task_metr = {\n",
    "    'dep': 'las',\n",
    "    'lmo': 'perplexity',\n",
    "    'ner': 'chunk_f1',\n",
    "    'pos': 'acc'\n",
    "}\n",
    "\n",
    "task_max = {\n",
    "    'dep': True,\n",
    "    'lmo': False,\n",
    "    'ner': True,\n",
    "    'pos': True\n",
    "}\n",
    "\n",
    "def draw_graphs(metric_func, tasks, langs, role, run_codes=None, run_types=None, focused=False):\n",
    "    fig, axes = plt.subplots(len(tasks), len(langs), figsize=(5*len(langs), 4*len(tasks)), squeeze=False)\n",
    "\n",
    "    relevant_runs = ['vanilla']\n",
    "\n",
    "    for task, lang in itertools.product(tasks, langs):\n",
    "        for run in runs:\n",
    "            if (\n",
    "                (not focused or run.config['focus_on'] == f'{task}-{lang}') and\n",
    "                (run_codes is None or run.code in run_codes) and\n",
    "                (run_types is None or run.type in run_types)\n",
    "            ):\n",
    "\n",
    "                history = run.history(\n",
    "                    metric=metric_func(task),\n",
    "                    task=task,\n",
    "                    language=lang,\n",
    "                    role=role)\n",
    "                axes[tasks.index(task), langs.index(lang)].plot(list(history), label=f'{run.code}-{run.type}')\n",
    "                #axes[tasks.index(task), langs.index(lang)].plot(list(history), label=run.type)\n",
    "\n",
    "    for ax, col in zip(axes[0], langs):\n",
    "        ax.set_title(col)\n",
    "\n",
    "    for ax, row in zip(axes[:, 0], tasks):\n",
    "        ax.set_ylabel(row, rotation=0, size='large')\n",
    "        \n",
    "    for ax_row in axes:\n",
    "        for ax in ax_row:\n",
    "            ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def find_runs(run_code=None, run_type=None, contains=None, **config):\n",
    "    \n",
    "    if contains is None:\n",
    "        contains = []\n",
    "    \n",
    "    return (run\n",
    "           for run\n",
    "           in runs\n",
    "           if  (run_code is None or run_code == run.code) and\n",
    "               (run_type is None or run_type == run.type) and\n",
    "               all(run.contains(*task_lang) for task_lang in contains) and\n",
    "               all(run.config[key] == value for key, value in config.items()))\n",
    "    \n",
    "    \n",
    "def print_results(runs, tasks, langs, metric_func=None, metric_max_func=None, focused=True):\n",
    "        \n",
    "    if metric_func is None:\n",
    "        metric_func = lambda task: task_metr[task]\n",
    "        \n",
    "    if metric_max_func is None:\n",
    "        metric_max_func = lambda task: task_max[task]\n",
    "        \n",
    "    output = []\n",
    "\n",
    "    for run in runs:\n",
    "        for task, lang in itertools.product(tasks, langs):\n",
    "            if not focused or run.config['focus_on'] == f'{task}-{lang}':\n",
    "                res, epoch = run.metric_eval(\n",
    "                    metric=metric_func(task),\n",
    "                    max_=metric_max_func(task),\n",
    "                    task=task,\n",
    "                    language=lang)\n",
    "                if res <= 1.01:\n",
    "                    res *= 100\n",
    "                print(task, lang, res, epoch)\n",
    "                output.append((res, epoch, run))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dep cs 43.605280994560275 6\n",
      "dep de 54.034936646573996 16\n",
      "dep en 44.37745316230324 13\n",
      "dep es 42.974757984257664 11\n",
      "dep cs 50.79800022013799 16\n",
      "dep de 59.945872801082544 29\n",
      "dep en 59.96843766438717 54\n",
      "dep es 62.354112005790284 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(50.79800022013799, 16, <run.Run at 0x7f3a6229e978>),\n",
       " (59.945872801082544, 29, <run.Run at 0x7f3a63dc8a58>),\n",
       " (59.96843766438717, 54, <run.Run at 0x7f3a621e7c88>),\n",
       " (62.354112005790284, 17, <run.Run at 0x7f3a64ad4128>)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks=['dep']\n",
    "print_results(\n",
    "    runs=find_runs(\n",
    "        run_type='all',\n",
    "        run_code='zero-shot'\n",
    "    ),\n",
    "    tasks=tasks,\n",
    "    langs=langs,\n",
    ")\n",
    "print_results(\n",
    "    runs=find_runs(\n",
    "        run_type='all',\n",
    "        run_code='zero-shot-task-lang-both-embs'\n",
    "    ),\n",
    "    tasks=tasks,\n",
    "    langs=langs,\n",
    ")\n",
    "\n",
    "# draw_graphs(lambda t: task_metr[t], tasks, langs, 'test', run_types=['all'], run_codes=[\n",
    "#     'zero-shot-task-emb',\n",
    "#     'zero-shot-lang-emb', \n",
    "#     'zero-shot-embs',\n",
    "#     'zero-shot',\n",
    "# ], focused=True)\n",
    "# draw_graphs(lambda t: task_metr[t], tasks, langs, 'test', run_types=['stsl'], run_codes=[\n",
    "#     'normal-training',\n",
    "# ])\n",
    "\n",
    "#draw_graphs(lambda t: 'ortho', tasks, langs, 'test', run_codes=[code])\n",
    "#print_results(find_runs(run_code=code), [task], [lang], lambda t: task_metr[t], lambda t: task_max[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
