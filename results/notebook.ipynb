{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('martak', 105), ('gcp', 62), ('deepnet2', 83), ('fiit-gcp-1', 10), ('fiit-gcp-2', 13), ('fiit-gcp-3', 14), ('acer', 30)]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from run import Run\n",
    "from runs_db import db as runs_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = '/home/mpikuliak/logs'\n",
    "runs = []\n",
    "\n",
    "for server in runs_db:\n",
    "    paths = glob.glob(os.path.join(log_path, server, '*'))\n",
    "    paths = iter(sorted(paths))\n",
    "\n",
    "    try:\n",
    "        for (number, type_, code) in runs_db[server]:\n",
    "            for _ in range(number):\n",
    "                try:\n",
    "                    path = next(paths)\n",
    "                    runs.append(Run(path, type_, code))\n",
    "                except KeyError:\n",
    "                    print(path)\n",
    "    except StopIteration:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['dep', 'lmo', 'ner', 'pos']\n",
    "langs = ['cs', 'de', 'en', 'es']\n",
    "\n",
    "task_metr = {\n",
    "    'dep': 'las',\n",
    "    'lmo': 'perplexity',\n",
    "    'ner': 'chunk_f1',\n",
    "    'pos': 'acc'\n",
    "}\n",
    "\n",
    "task_max = {\n",
    "    'dep': True,\n",
    "    'lmo': False,\n",
    "    'ner': True,\n",
    "    'pos': True\n",
    "}\n",
    "\n",
    "def draw_graphs(metric_func, tasks, langs, role, run_codes=None, run_types=None):\n",
    "    fig, axes = plt.subplots(len(tasks), len(langs), figsize=(5*len(langs), 4*len(tasks)), squeeze=False)\n",
    "\n",
    "    relevant_runs = ['vanilla']\n",
    "\n",
    "    for task, lang in itertools.product(tasks, langs):\n",
    "        for run in runs:\n",
    "            if (\n",
    "                run.contains(task, lang) and\n",
    "                (run_codes is None or run.code in run_codes) and\n",
    "                (run_types is None or run.type in run_types)\n",
    "            ):\n",
    "\n",
    "                history = run.history(\n",
    "                    metric=metric_func(task),\n",
    "                    task=task,\n",
    "                    language=lang,\n",
    "                    role=role)\n",
    "                axes[tasks.index(task), langs.index(lang)].plot(list(history), label=f'{run.code}-{run.type}')\n",
    "\n",
    "    for ax, col in zip(axes[0], langs):\n",
    "        ax.set_title(col)\n",
    "\n",
    "    for ax, row in zip(axes[:, 0], tasks):\n",
    "        ax.set_ylabel(row, rotation=0, size='large')\n",
    "        \n",
    "    for ax_row in axes:\n",
    "        for ax in ax_row:\n",
    "            ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def print_results(metric_func, metric_max_func, tasks, langs, run_codes=None, run_types=None, print_lambda=None):\n",
    "    \n",
    "    if print_lambda is None:\n",
    "        print_lambda = lambda val, run: print(f'{val:.2f}')\n",
    "        \n",
    "    output = []\n",
    "    \n",
    "    for task, lang in itertools.product(tasks, langs):\n",
    "        for run in runs:\n",
    "            if (\n",
    "                run.contains(task, lang) and\n",
    "                (run_codes is None or run.code in run_codes) and\n",
    "                (run_types is None or run.type in run_types)\n",
    "            ):\n",
    "                result = run.metric_eval(\n",
    "                    metric=metric_func(task),\n",
    "                    max_=metric_max_func(task),\n",
    "                    task=task,\n",
    "                    language=lang)\n",
    "                res = result[0]\n",
    "                if res < 1.01:\n",
    "                    res *= 100\n",
    "                print_lambda(res, run)\n",
    "                output.append((res, run))\n",
    "                \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['cs'],\n",
    "     ['private-focused-0.75'], ['ml'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['es'],\n",
    "     ['private-focused'], ['ml'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['ner'], ['cs'],\n",
    "     ['vanilla'], ['mt'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print('87.69 /home/fiit/logs/acer/2019-02-22-025619')\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['pos'], ['cs'],\n",
    "     ['no-adv-tsh-focused-0.75'], ['mt'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['pos'], ['es'],\n",
    "     ['no-adv-tsh-focused'], ['mt'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print()\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['de'],\n",
    "     ['private'], ['mt'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['en'],\n",
    "     ['private'], ['ml'], lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print('83.07 /home/fiit/logs/deepnet2/2019-02-26-041529')\n",
    "print('85.07 /home/fiit/logs/acer/2019-02-20-213852')\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['pos'], ['de'],\n",
    "     ['vanilla'], ['mt'], print_lambda=lambda val, run: print(f'{val:.2f} {run.path}'))\n",
    "\n",
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], ['pos'], ['en'],\n",
    "     ['private'], ['mt'], print_lambda=lambda val, run: print(f'{val:.2f} {run.path}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graphs(lambda task: task_metr[task], tasks, langs, 'test',\n",
    "#              ['private-focused-200', 'no-adv-tsh-200'], ['ml'])\n",
    "draw_graphs(lambda _: 'unit_strength_2', tasks, langs, 'test',\n",
    "             ['private', 'no-adv-task-sharing'], ['ml', 'mt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [('dep','cs'), ('dep','es'), ('ner','cs'), ('ner','es'), ('pos','cs'), ('pos','es'),]\n",
    "\n",
    "def print_row(code, type_):\n",
    "    for t, l in pairs:\n",
    "        print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                    [code], [type_], lambda val, run: print(f'{val:.2f}', end=' '))\n",
    "\n",
    "codes = ['private-focused', 'no-adv-tsh-focused']\n",
    "types = ['ml', 'mt']\n",
    "\n",
    "for code in codes:\n",
    "    for type_ in types:\n",
    "        print(f'{code}{type_}', end='\\t')\n",
    "        print_row(code, type_)\n",
    "        print()\n",
    "        \n",
    "codes = ['private-focused-0.75', 'no-adv-tsh-focused-0.75']\n",
    "types = ['ml', 'mt']\n",
    "\n",
    "for code in codes:\n",
    "    for type_ in types:\n",
    "        print(f'{code}{type_}', end='\\t\\t')\n",
    "        print_row(code, type_)\n",
    "        print()\n",
    "        \n",
    "codes = ['private-focused-0.75', 'no-adv-tsh-focused-0.75', 'private-focused', 'no-adv-tsh-focused']\n",
    "types = ['mtml']\n",
    "\n",
    "for code in codes:\n",
    "    for type_ in types:\n",
    "        print(f'{code}{type_}', end='\\t\\t')\n",
    "        print_row(code, type_)\n",
    "        print()\n",
    "\n",
    "\n",
    "# print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['en'],\n",
    "#             ['dep-adv-lambda-0.25'])\n",
    "# print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['en'],\n",
    "#             ['dep-adv-lambda-0.125'])\n",
    "# print_results(lambda task: task_metr[task], lambda task: task_max[task], ['dep'], ['en'],\n",
    "#             ['no-adv-task-sharing'], ['ml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pairs = list(itertools.product(['dep', 'ner', 'pos'], langs))\n",
    "\n",
    "def print_row(code, type_, msg):\n",
    "    print(msg, end=' ')\n",
    "    for t, l in pairs:\n",
    "        print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                    [code], [type_], lambda val, run: print(f'{val:.2f}', end=' '))\n",
    "    print()\n",
    "        \n",
    "print_row('vanilla', 'stsl', 'Baseline')\n",
    "\n",
    "print('Best1', end=' ')\n",
    "for t, l in pairs:\n",
    "    output = print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                ['one-aux'], print_lambda=lambda _, __: ...)\n",
    "    print(f'{max([r[0] for r in output]):.2f}', end=' ')\n",
    "print()\n",
    "\n",
    "print('Avg', end=' ')\n",
    "for t, l in pairs:\n",
    "    output = print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                ['one-aux'], print_lambda=lambda _, __: ...)\n",
    "    print(f'{np.mean([r[0] for r in output]):.2f}', end=' ')\n",
    "print()\n",
    "\n",
    "\n",
    "print('Worst1', end=' ')\n",
    "for t, l in pairs:\n",
    "    output = print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                ['one-aux'], print_lambda=lambda _, __: ...)\n",
    "    print(f'{min([r[0] for r in output]):.2f}', end=' ')\n",
    "print()\n",
    "\n",
    "print_row('vanilla', 'mt', 'A-MT')\n",
    "print_row('no-adv-task-sharing', 'ml', 'A-ML')\n",
    "print_row('no-adv-task-sharing', 'mtml', 'A-MTML')\n",
    "print_row('private', 'mt', 'B-MT')\n",
    "print_row('private', 'ml', 'B-ML')\n",
    "print_row('private', 'mtml', 'B-MTML')\n",
    "print_row('no-adv', 'ml', 'C-ML')\n",
    "print_row('no-adv', 'mtml', 'C-MTML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t, l in pairs:\n",
    "    output = print_results(lambda task: task_metr[task], lambda task: task_max[task], [t], [l],\n",
    "                ['one-aux'], print_lambda=lambda _, __: ...)\n",
    "    output = sorted(output, key=lambda r: -r[0])\n",
    "    print(output[0][1].hparams['tasks'])\n",
    "    #print(f'{max([r[0] for r in output]):.2f}', end=' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graphs(lambda task: task_metr[task], tasks, langs, 'test', ['vanilla'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.69 dep-cs\n",
      "80.23 dep-de\n",
      "86.77 dep-es\n",
      "82.64 ner-de\n",
      "99.08 pos-cs\n",
      "96.73 pos-es\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(89.6894316384639, <run.Run at 0x7fb915cd83c8>),\n",
       " (80.23127075901095, <run.Run at 0x7fb9177ffda0>),\n",
       " (86.772821858319, <run.Run at 0x7fb915de6748>),\n",
       " (82.63649778652238, <run.Run at 0x7fb914ff7f28>),\n",
       " (99.07599974510337, <run.Run at 0x7fb9154b6048>),\n",
       " (96.73391839319642, <run.Run at 0x7fb91500ca20>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(lambda task: task_metr[task], lambda task: task_max[task], tasks, langs,\n",
    "     ['fine-tune'], print_lambda=lambda val, run: print(f'{val:.2f} {run.hparams[\"train_only\"]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
