# Preprocessing

Slova pri spracovani na urovni znakov berieme do maximalnej dlzky 30.
Dlzka vety je maximalne 70, minimalne 2.

## POS
- vsetko z UD datasetu
- pri CZ sme spojili vsetky train do jedneho
- niektore mali rozlicne spojene slova (de el > del v spanielcine), tu sme zobrali len rozobrane slova.
- v anglickom boli niektore slova presunute, pokial sa na to odkazovalo v text neskor (8.1), tieto som ignoroval

## NER
- english - CoNLL'03 (PER, LOC, ORG, MISC)
    - toto neplati, zobral som nejaky iny dataset a dal som ho 80-10-10 - treba pozriet preprocessing script
- spanish - CoNLL'02 (PER, LOC, ORG, MISC)
- german - germeval (PER, LOC, ORG, MISC)
- czech - czech named entity corpus (p - PER, g - LOC, i+ms - ORG, oa+op - MISC)
- only first level annotation (v Germeval mali aj second level, cize napr. v Univercity Jena bola Jena aj cast ORG, ale zaroven aj LOC)
- Xpart (cast je NER nazov) a Xderiv (odvodene slova) vyhodene
- v anotovani su nezrovnalosti, nemecky napr. anotuju omnoho viac javov ako anglicky (vratane napr. nazvov mien, znaciek)
- vsetky konvertovat na BIO + PLOM
- odstranene vety, kde viac ako 50% tvorili cisla

## DEP
- podobne ako pri POS beriem do uvahy tie slova z UD, ktore maju svoje id. Rozlicne zhluky neberieme do uvahy
- z labelov vztahov berieme len prvu cast, druhu language-specific ignorujeme

# NLI
- odstranili sme vsetky dvojice bez golden tagu

# LMO
- europarl, english zo spanielskej verzie
- train/dev/test 95 - 2.5 - 2.5


# Semantic Role Labeling
Velmi zaujimavo vyzerajuci task, ale dostupne data stoja 2000+ eur.


# Klasifikacia dokumentov
Tento task predbezne zavrhujem. Vidim tam len maly suvis s inymi ulohami. Empiricky sa navyse ukazuje,
ze bag of words pristupy su tu stale top, co nenaznacuje ze by LSTM model mohol byt aj s inymi datami
velmi uspesny.
Mozny zdroj dat: A Corpus for Multilingual Document Classification in Eight Languages


# NLI anglicke vysledky
Pre anglictinu davam 82%, co je na urovni jednoducheho porovnatelneho baseline (stranka SNLI)


# Learning rate scheduling
Experimentoval som s exponential decay:
0.95 exp decay mal horsie vysledky
0.99 a static mali prakticky rovnake


# Konvolucna siet na znakoch
Nedokazal som prekonat vysledky LSTM, pricom som zaznamenal len male zrychlenie (cca 2%).
Je tazke ale vystopovat, ake su best practices pri takomto modeli.


# Vysledky z grid search

Adam vs. RMSProp - Pri dependency parsingu bol jednoznacne lepsi Adam.
Pri POS bol lepsi vo vacsine pripadov, aj ked vysledky sa lisili len malo.
Pri NER vysledky skakali hore dole a tazko rozhodnut, co bolo lepsie.
Zaver: ADAM

Batch size 8 16 32
Pri DEP jednoznacne dominuje 32, prave tu si ale vacsi nemozno dovolit
Pri POS to sa to dost myli, ale zda sa ze vacsi batch_size dominuje pri mensom learning_rate
Pri NER podobne ako POS, aj ked dominancia pri mensom learning_rate je este viac viditelna
Dominancia POS a NER mozu byt sposobena mensim poctom epoch. Viac dat sa tak pri malom learning_rate moze dost osvedcit.
Zaver: 32, skusime experimentovat s vacsim poctom navzdory DEP
Update: Viac sa ukazalo pre POS aj NER ako nevhodne. 32 je nateraz finalne cislo.

Learning rate 0.003, 0.001, 0.0003
0.0003 sa ukazalo ako jednoznacne maly learning rate.
0.003 sa zda byt najlepsi, ALE treba skusit mono este vacsi.
A zaroven, vo viacerych pripadoch nebol model dotrenovany.
Zaver: Treba dalsie experimenty, predbezne nastavujem learning_rate na 0.003

Batch size aj learning rate sa ukazali ako pomerne citlive parametre. Na toto si treba dat pozor.
DP bol nedotrenovany, 30 epoch moze byt prilis malo.

# Float16
Chcel som skusit namiesto float32 pouzit float16. Zo znizenymi pamatovymi narokmi by som potom mozno dokazal spustat
DEP aj s vacsou batch size. Bohuzial viacere komponenty z contribu float16 vobec nepripustaju, napr. CUDNN LSTM alebo
CRF loss. Stalo by za to pozriet sa, ci toto nie je adresovane v novsej verzii tensorflow.

# Rozlicne casy spracovania datasetov
Pri NER-es a NER-de som spozoroval velky rozdiel v case spracovania epochy. Spanielske vety su ale na dlzku v priemere
2x take dlhe. Je to zrejme sposobene rozlicnou domenou datasetu.

# ML MT experiment
Vysledky z ML MT su prekvapivo zle. Vo vela ulohach sa nachadzaju na takej urovni, aku SL ST dosiahlo po par epochach.
Model ma zrejme velke problemy vysporiadat sa so zmenami v domene a skonvergovat ku niecomu inteligentnemu.
Niekolko napadov ako to zachranit:
1) Experiment kde jeden jazyk bude low resource
2) Experiment kde sa jeden jazyk bude vyberat viac ako ostatne
3) Experiment kde sa natrenuje ML MT model a potom sa dotrenuje pre jednotlive ulohy
4) Pre istotu iba ML a MT experimenty
5) learning_rate tuning

Ad 1: Pri cestine sa ukazalo ze niekde medzi 500 a 5000 training samplov sa viac oplati pouzit MLMT pristup.
Pozitivny transfer tam teda prebieha, ale len pri low resource. Inak je stale vyhodnejsie mat data z identickej domeny.
Pri fine-tuningu dokazem SL-ST porazat aj pri 5-15k training samploch.

Ad 3: Pre prilis malo dat to vysledky pochopitelne zhorsilo. Pre stredne mnozstvo to jasne pomohlo.
Pre velke mnozstvo dat to vela nespravilo. Moze byt v poslednom pripade problem s tym, ze sa s modelom inicializuju aj
Adam-related parametre ktore potom spomalia ucenie?

Ad 4: Pre DEP a NER sa lepsie ako MLMT javi cisto ML. Problem ale moze byt v tom, ze pri MT a MLMT obmedzujem velkost
in-language uloh.

Stale sa ukazuje, ze tie modely su nedotrenovane. Namiesto fixneho casu treba pokial je to mozne zaviest early stopping.

Pri dotrenovani nezalezi na tom, ci zresetujem Adam-related premenne. Vysledky su prakticky totozne.

Co treba skusit:
- MLMT bez taskov, ktore nijako nesuvisia s target taskom (chceme porazit ML)
- SLST s lr resetom
- MLMT a MT s tym ze obmedzuje iba velkost target task dat (chceme porazit ML)


# daj do prace
full dep uas dev
Po 30 epochach sa stale nevyrovnali SLST - lokalne optimum z ktoreho sa nevedia dostat?

pri 5000 a 500 su tie vizualizacie tiez zaujimave

pri sledovani metrik na train-dev je jasne, ze MLMT ma problem ich overfitnut, je tam privela signalu navyse, ktory to od optima odtrha. Opat to iste, ani po 30 epochach sa to nedostalo pri fitovani train dat na uroven SLST. - Je to poducene alebo v lokalnom?

To ze je to horsie naucene badat aj pri analyze loss.

LOSS 500
Pri POS sa sprava ako sa ocakava - po prechode na fine tuning zacne rapidne stupat, pricom skore klesa
Pri NER azcne stupat najme pri ML*, ale skore sa aj tak zlepsuje pri fine tuningu.
Pri DEP sa tiez vyrazne zlepsi skore, napriek stupajucej chybe.

# zavery
- ML sa ukazalo velmi silne, napriek tomu ze mame pomerne cudzie jazyky
- MT treba lepsi pristup, toto takyto jednoduchy mdoel nezvlada
- MLMT trpi nedostatkami MT, ale zaroven prebera z ML dobre vysledky - chcelo by to s tym MT zatocit
- pre POS a DEP mame sota vysledky, ale SLST modelom

